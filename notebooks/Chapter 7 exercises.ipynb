{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. If you have trained five different models on the exact same training data, and they all achieve 95% precision, is there any chance that you can combine these models to get better results? If so, how? If not, why?\n",
    "\n",
    "A. Yes - they may have made different errors so modal results may improve the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. What is the difference between hard and soft voting classifiers?\n",
    "\n",
    "A.\n",
    "- hard uses the modal classification\n",
    "- soft uses the combined mean probabilities to wieght the vote so high confidence votes count for more\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. Is it possible to speed up training of a bagging ensemble by distributing it across multiple servers? What about pasting ensembles, boosting ensembles, random forests, or stacking ensembles?\n",
    "\n",
    "A. \n",
    "- Bagging; yes models can be trainined in parrallel as they are independent\n",
    "- pasting; yes\n",
    "- boosting; no - models need to be sequentially trained\n",
    "- random forests - yes\n",
    "- stacking - yes models on different layers can be trained in parrallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. What is the benefit of out-of-bag evaluation?\n",
    "\n",
    "A. A 'free' out-of-sample estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. What makes Extra-Trees more random than regular Random Forests? How can this extra randomness help? Are Extra-Trees slower or faster than regular Random Forests?\n",
    "\n",
    "They pick random thresholds at each node. This speeds up training considerably and can perform better if random forest is overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. If your AdaBoost ensemble underfits the training data, what hyperparameters should you tweak and how?\n",
    "\n",
    "A. Number of estimators as more may be required to find a good solution, and reduce regularization of the inital estimator to free up model params for more tweaking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. If your Gradient Boosting ensemble overfits the training set, should you increase or decrease the learning rate?\n",
    "\n",
    "A. Decrease, may be 'jumping' past the best model. Also try early stopping as the best model is unlikely to be the final one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. Load the MNIST data (introduced in Chapter 3), and split it into a training set, a validation set, and a test set (e.g., use 50,000 instances for training, 10,000 for validation, and 10,000 for testing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0803 11:50:30.973899 139732972889856 deprecation.py:323] From <ipython-input-1-1b917109a13c>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0803 11:50:30.974681 139732972889856 deprecation.py:323] From /home/edd/.local/share/virtualenvs/ml_projects-PtpjDyvs/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0803 11:50:30.975424 139732972889856 deprecation.py:323] From /home/edd/.local/share/virtualenvs/ml_projects-PtpjDyvs/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0803 11:50:31.175099 139732972889856 deprecation.py:323] From /home/edd/.local/share/virtualenvs/ml_projects-PtpjDyvs/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0803 11:50:31.214300 139732972889856 deprecation.py:323] From /home/edd/.local/share/virtualenvs/ml_projects-PtpjDyvs/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "\n",
    "X_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "X = np.concatenate([X_train, X_test])\n",
    "y = np.concatenate([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_to_split, X_val, y_to_split, y_val = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        train_size=55000,\n",
    "                                                        random_state=42,\n",
    "                                                        stratify=y) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_to_split,\n",
    "                                                    y_to_split,\n",
    "                                                    train_size=45000,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y_to_split) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then train various classifiers, such as a Random Forest classifier, an Extra-Trees classifier, and an SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import SCORERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'accuracy', 'roc_auc', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'brier_score_loss', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random_params = {\"n_estimators\": np.linspace(10,500,490).astype(int),\n",
    "             \"criterion\":[\"gini\", \"entropy\"],\n",
    "             \"max_depth\": np.linspace(1,5,4),\n",
    "             \"max_features\": np.linspace(0.1,1,100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=42,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rand = RandomizedSearchCV(rf_clf,\n",
    "                             rf_random_params,\n",
    "                             n_iter=250,\n",
    "                             scoring=\"balanced_accuracy\",\n",
    "                             n_jobs=-1,\n",
    "                             cv=3,\n",
    "                             verbose=10,\n",
    "                             random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 250 candidates, totalling 750 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 21.7min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 26.9min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 45.6min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 57.3min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 71.6min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 83.4min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 86.8min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 93.2min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 100.9min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 116.7min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 132.1min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 140.8min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 148.2min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 171.0min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed: 182.0min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed: 194.3min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 200.8min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed: 217.1min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed: 234.1min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 256.9min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed: 282.7min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed: 310.8min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 332.8min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed: 347.7min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed: 358.4min\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed: 400.6min\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed: 421.6min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed: 447.6min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed: 474.3min\n",
      "[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed: 491.5min\n",
      "[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed: 537.9min\n",
      "[Parallel(n_jobs=-1)]: Done 750 out of 750 | elapsed: 584.7min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 63\n",
      "building tree 4 of 63\n",
      "building tree 5 of 63\n",
      "building tree 6 of 63\n",
      "building tree 7 of 63\n",
      "building tree 8 of 63\n",
      "building tree 9 of 63\n",
      "building tree 10 of 63\n",
      "building tree 11 of 63\n",
      "building tree 12 of 63\n",
      "building tree 13 of 63\n",
      "building tree 14 of 63\n",
      "building tree 15 of 63\n",
      "building tree 16 of 63\n",
      "building tree 17 of 63\n",
      "building tree 18 of 63\n",
      "building tree 19 of 63\n",
      "building tree 20 of 63\n",
      "building tree 21 of 63\n",
      "building tree 22 of 63\n",
      "building tree 23 of 63\n",
      "building tree 24 of 63\n",
      "building tree 25 of 63\n",
      "building tree 26 of 63\n",
      "building tree 27 of 63\n",
      "building tree 28 of 63\n",
      "building tree 29 of 63\n",
      "building tree 30 of 63\n",
      "building tree 31 of 63\n",
      "building tree 32 of 63\n",
      "building tree 33 of 63\n",
      "building tree 34 of 63\n",
      "building tree 35 of 63\n",
      "building tree 36 of 63\n",
      "building tree 37 of 63\n",
      "building tree 38 of 63\n",
      "building tree 39 of 63\n",
      "building tree 40 of 63\n",
      "building tree 41 of 63\n",
      "building tree 42 of 63\n",
      "building tree 43 of 63\n",
      "building tree 44 of 63\n",
      "building tree 45 of 63\n",
      "building tree 46 of 63\n",
      "building tree 47 of 63\n",
      "building tree 48 of 63\n",
      "building tree 49 of 63\n",
      "building tree 50 of 63\n",
      "building tree 51 of 63\n",
      "building tree 52 of 63\n",
      "building tree 53 of 63\n",
      "building tree 54 of 63\n",
      "building tree 55 of 63\n",
      "building tree 56 of 63\n",
      "building tree 57 of 63\n",
      "building tree 58 of 63\n",
      "building tree 59 of 63\n",
      "building tree 60 of 63\n",
      "building tree 61 of 63\n",
      "building tree 62 of 63\n",
      "building tree 63 of 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed:   25.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators='warn',\n",
       "                                                    n_jobs=None,\n",
       "                                                    oob_sc...\n",
       "       439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451,\n",
       "       452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464,\n",
       "       465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477,\n",
       "       478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490,\n",
       "       491, 492, 493, 494, 495, 496, 497, 498, 500])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring='balanced_accuracy',\n",
       "                   verbose=10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_rand.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "y_rf_preds = rf_rand.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8412291145370604"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_train, y_rf_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "y_rf_test_preds = rf_rand.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8314416735561345"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_test, y_rf_test_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 63,\n",
       " 'max_features': 0.14545454545454545,\n",
       " 'max_depth': 5.0,\n",
       " 'criterion': 'gini'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_rand.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\"n_estimators\": [x for x in range(20,200,20)],\n",
    "             \"criterion\":[\"entropy\"],\n",
    "             \"max_depth\": [3,4,5],\n",
    "             \"max_features\": [x for x in np.arange(0.05,0.26,0.05)] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid = GridSearchCV(rf_clf, rf_params, verbose=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 135 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edd/.local/share/virtualenvs/ml_projects-PtpjDyvs/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   58.9s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 19.0min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 22.4min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed: 30.4min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 35.0min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed: 37.0min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 45.9min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed: 53.2min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed: 61.8min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 180\n",
      "building tree 2 of 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 180\n",
      "building tree 4 of 180\n",
      "building tree 5 of 180\n",
      "building tree 6 of 180\n",
      "building tree 7 of 180\n",
      "building tree 8 of 180\n",
      "building tree 9 of 180\n",
      "building tree 10 of 180\n",
      "building tree 11 of 180\n",
      "building tree 12 of 180\n",
      "building tree 13 of 180\n",
      "building tree 14 of 180\n",
      "building tree 15 of 180\n",
      "building tree 16 of 180\n",
      "building tree 17 of 180\n",
      "building tree 18 of 180\n",
      "building tree 19 of 180\n",
      "building tree 20 of 180\n",
      "building tree 21 of 180\n",
      "building tree 22 of 180\n",
      "building tree 23 of 180\n",
      "building tree 24 of 180\n",
      "building tree 25 of 180\n",
      "building tree 26 of 180\n",
      "building tree 27 of 180\n",
      "building tree 28 of 180\n",
      "building tree 29 of 180\n",
      "building tree 30 of 180\n",
      "building tree 31 of 180\n",
      "building tree 32 of 180\n",
      "building tree 33 of 180\n",
      "building tree 34 of 180\n",
      "building tree 35 of 180\n",
      "building tree 36 of 180\n",
      "building tree 37 of 180\n",
      "building tree 38 of 180\n",
      "building tree 39 of 180\n",
      "building tree 40 of 180\n",
      "building tree 41 of 180\n",
      "building tree 42 of 180\n",
      "building tree 43 of 180\n",
      "building tree 44 of 180\n",
      "building tree 45 of 180\n",
      "building tree 46 of 180\n",
      "building tree 47 of 180\n",
      "building tree 48 of 180\n",
      "building tree 49 of 180\n",
      "building tree 50 of 180\n",
      "building tree 51 of 180\n",
      "building tree 52 of 180\n",
      "building tree 53 of 180\n",
      "building tree 54 of 180\n",
      "building tree 55 of 180\n",
      "building tree 56 of 180\n",
      "building tree 57 of 180\n",
      "building tree 58 of 180\n",
      "building tree 59 of 180\n",
      "building tree 60 of 180\n",
      "building tree 61 of 180\n",
      "building tree 62 of 180\n",
      "building tree 63 of 180\n",
      "building tree 64 of 180\n",
      "building tree 65 of 180\n",
      "building tree 66 of 180\n",
      "building tree 67 of 180\n",
      "building tree 68 of 180\n",
      "building tree 69 of 180\n",
      "building tree 70 of 180\n",
      "building tree 71 of 180\n",
      "building tree 72 of 180\n",
      "building tree 73 of 180\n",
      "building tree 74 of 180\n",
      "building tree 75 of 180\n",
      "building tree 76 of 180\n",
      "building tree 77 of 180\n",
      "building tree 78 of 180\n",
      "building tree 79 of 180\n",
      "building tree 80 of 180\n",
      "building tree 81 of 180\n",
      "building tree 82 of 180\n",
      "building tree 83 of 180\n",
      "building tree 84 of 180\n",
      "building tree 85 of 180\n",
      "building tree 86 of 180\n",
      "building tree 87 of 180\n",
      "building tree 88 of 180\n",
      "building tree 89 of 180\n",
      "building tree 90 of 180\n",
      "building tree 91 of 180\n",
      "building tree 92 of 180\n",
      "building tree 93 of 180\n",
      "building tree 94 of 180\n",
      "building tree 95 of 180\n",
      "building tree 96 of 180\n",
      "building tree 97 of 180\n",
      "building tree 98 of 180\n",
      "building tree 99 of 180\n",
      "building tree 100 of 180\n",
      "building tree 101 of 180\n",
      "building tree 102 of 180\n",
      "building tree 103 of 180\n",
      "building tree 104 of 180\n",
      "building tree 105 of 180\n",
      "building tree 106 of 180\n",
      "building tree 107 of 180\n",
      "building tree 108 of 180\n",
      "building tree 109 of 180\n",
      "building tree 110 of 180\n",
      "building tree 111 of 180\n",
      "building tree 112 of 180\n",
      "building tree 113 of 180\n",
      "building tree 114 of 180\n",
      "building tree 115 of 180\n",
      "building tree 116 of 180\n",
      "building tree 117 of 180\n",
      "building tree 118 of 180\n",
      "building tree 119 of 180\n",
      "building tree 120 of 180\n",
      "building tree 121 of 180\n",
      "building tree 122 of 180\n",
      "building tree 123 of 180\n",
      "building tree 124 of 180\n",
      "building tree 125 of 180\n",
      "building tree 126 of 180\n",
      "building tree 127 of 180\n",
      "building tree 128 of 180\n",
      "building tree 129 of 180\n",
      "building tree 130 of 180\n",
      "building tree 131 of 180\n",
      "building tree 132 of 180\n",
      "building tree 133 of 180\n",
      "building tree 134 of 180\n",
      "building tree 135 of 180\n",
      "building tree 136 of 180\n",
      "building tree 137 of 180\n",
      "building tree 138 of 180\n",
      "building tree 139 of 180\n",
      "building tree 140 of 180\n",
      "building tree 141 of 180\n",
      "building tree 142 of 180\n",
      "building tree 143 of 180\n",
      "building tree 144 of 180\n",
      "building tree 145 of 180\n",
      "building tree 146 of 180\n",
      "building tree 147 of 180\n",
      "building tree 148 of 180\n",
      "building tree 149 of 180\n",
      "building tree 150 of 180\n",
      "building tree 151 of 180\n",
      "building tree 152 of 180\n",
      "building tree 153 of 180\n",
      "building tree 154 of 180\n",
      "building tree 155 of 180\n",
      "building tree 156 of 180\n",
      "building tree 157 of 180\n",
      "building tree 158 of 180\n",
      "building tree 159 of 180\n",
      "building tree 160 of 180\n",
      "building tree 161 of 180\n",
      "building tree 162 of 180\n",
      "building tree 163 of 180\n",
      "building tree 164 of 180\n",
      "building tree 165 of 180\n",
      "building tree 166 of 180\n",
      "building tree 167 of 180\n",
      "building tree 168 of 180\n",
      "building tree 169 of 180\n",
      "building tree 170 of 180\n",
      "building tree 171 of 180\n",
      "building tree 172 of 180\n",
      "building tree 173 of 180\n",
      "building tree 174 of 180\n",
      "building tree 175 of 180\n",
      "building tree 176 of 180\n",
      "building tree 177 of 180\n",
      "building tree 178 of 180\n",
      "building tree 179 of 180\n",
      "building tree 180 of 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:   36.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False, random_state=42,\n",
       "                                              verbose=3, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'criterion': ['entropy'], 'max_depth': [3, 4, 5],\n",
       "                         'max_features': [0.05, 0.1, 0.15000000000000002, 0.2,\n",
       "                                          0.25],\n",
       "                         'n_estimators': [20, 40, 60, 80, 100, 120, 140, 160,\n",
       "                                          180]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 5,\n",
       " 'max_features': 0.05,\n",
       " 'n_estimators': 180}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:    1.2s finished\n"
     ]
    }
   ],
   "source": [
    "y_rf_train_pred = rf_grid.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8540817639406963"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_train, y_rf_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "y_rf_test_pred = rf_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8479108309726741"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_test, y_rf_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bit of an improvement there, lets try extra trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_random_params = {\"n_estimators\": np.linspace(10,500,490).astype(int),\n",
    "             \"criterion\":[\"gini\", \"entropy\"],\n",
    "             \"max_depth\": np.linspace(1,5,4),\n",
    "             \"max_features\": np.linspace(0.1,1,100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_clf = ExtraTreesClassifier(random_state=42,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_rand = RandomizedSearchCV(et_clf,\n",
    "                             et_random_params,\n",
    "                             n_iter=250,\n",
    "                             scoring=\"balanced_accuracy\",\n",
    "                             n_jobs=-1,\n",
    "                             cv=3,\n",
    "                             verbose=10,\n",
    "                             random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 250 candidates, totalling 750 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 23.7min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 25.0min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 32.0min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 52.9min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 61.6min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 75.1min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 90.0min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 94.6min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 101.8min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 112.1min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 129.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 145.0min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 154.3min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 162.3min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 184.2min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed: 195.7min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed: 213.8min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 222.8min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed: 243.4min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed: 262.6min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 291.4min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed: 318.1min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed: 344.1min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 370.4min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed: 388.8min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed: 402.6min\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed: 445.4min\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed: 467.1min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed: 502.6min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed: 530.2min\n",
      "[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed: 548.3min\n",
      "[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed: 599.7min\n",
      "[Parallel(n_jobs=-1)]: Done 750 out of 750 | elapsed: 653.4min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 215\n",
      "building tree 4 of 215\n",
      "building tree 5 of 215\n",
      "building tree 6 of 215\n",
      "building tree 7 of 215\n",
      "building tree 8 of 215\n",
      "building tree 9 of 215\n",
      "building tree 10 of 215\n",
      "building tree 11 of 215\n",
      "building tree 12 of 215\n",
      "building tree 13 of 215\n",
      "building tree 14 of 215\n",
      "building tree 15 of 215\n",
      "building tree 16 of 215\n",
      "building tree 17 of 215\n",
      "building tree 18 of 215\n",
      "building tree 19 of 215\n",
      "building tree 20 of 215\n",
      "building tree 21 of 215\n",
      "building tree 22 of 215\n",
      "building tree 23 of 215\n",
      "building tree 24 of 215\n",
      "building tree 25 of 215\n",
      "building tree 26 of 215\n",
      "building tree 27 of 215\n",
      "building tree 28 of 215\n",
      "building tree 29 of 215\n",
      "building tree 30 of 215\n",
      "building tree 31 of 215\n",
      "building tree 32 of 215\n",
      "building tree 33 of 215\n",
      "building tree 34 of 215\n",
      "building tree 35 of 215\n",
      "building tree 36 of 215\n",
      "building tree 37 of 215\n",
      "building tree 38 of 215\n",
      "building tree 39 of 215\n",
      "building tree 40 of 215\n",
      "building tree 41 of 215\n",
      "building tree 42 of 215\n",
      "building tree 43 of 215\n",
      "building tree 44 of 215\n",
      "building tree 45 of 215\n",
      "building tree 46 of 215\n",
      "building tree 47 of 215\n",
      "building tree 48 of 215\n",
      "building tree 49 of 215\n",
      "building tree 50 of 215\n",
      "building tree 51 of 215\n",
      "building tree 52 of 215\n",
      "building tree 53 of 215\n",
      "building tree 54 of 215\n",
      "building tree 55 of 215\n",
      "building tree 56 of 215\n",
      "building tree 57 of 215\n",
      "building tree 58 of 215\n",
      "building tree 59 of 215\n",
      "building tree 60 of 215\n",
      "building tree 61 of 215\n",
      "building tree 62 of 215\n",
      "building tree 63 of 215\n",
      "building tree 64 of 215\n",
      "building tree 65 of 215\n",
      "building tree 66 of 215\n",
      "building tree 67 of 215\n",
      "building tree 68 of 215\n",
      "building tree 69 of 215\n",
      "building tree 70 of 215\n",
      "building tree 71 of 215\n",
      "building tree 72 of 215\n",
      "building tree 73 of 215\n",
      "building tree 74 of 215\n",
      "building tree 75 of 215\n",
      "building tree 76 of 215\n",
      "building tree 77 of 215\n",
      "building tree 78 of 215\n",
      "building tree 79 of 215\n",
      "building tree 80 of 215\n",
      "building tree 81 of 215\n",
      "building tree 82 of 215\n",
      "building tree 83 of 215\n",
      "building tree 84 of 215\n",
      "building tree 85 of 215\n",
      "building tree 86 of 215\n",
      "building tree 87 of 215\n",
      "building tree 88 of 215\n",
      "building tree 89 of 215\n",
      "building tree 90 of 215\n",
      "building tree 91 of 215\n",
      "building tree 92 of 215\n",
      "building tree 93 of 215\n",
      "building tree 94 of 215\n",
      "building tree 95 of 215\n",
      "building tree 96 of 215\n",
      "building tree 97 of 215\n",
      "building tree 98 of 215\n",
      "building tree 99 of 215\n",
      "building tree 100 of 215\n",
      "building tree 101 of 215\n",
      "building tree 102 of 215\n",
      "building tree 103 of 215\n",
      "building tree 104 of 215\n",
      "building tree 105 of 215\n",
      "building tree 106 of 215\n",
      "building tree 107 of 215\n",
      "building tree 108 of 215\n",
      "building tree 109 of 215\n",
      "building tree 110 of 215\n",
      "building tree 111 of 215\n",
      "building tree 112 of 215\n",
      "building tree 113 of 215\n",
      "building tree 114 of 215\n",
      "building tree 115 of 215\n",
      "building tree 116 of 215\n",
      "building tree 117 of 215\n",
      "building tree 118 of 215\n",
      "building tree 119 of 215\n",
      "building tree 120 of 215\n",
      "building tree 121 of 215\n",
      "building tree 122 of 215\n",
      "building tree 123 of 215\n",
      "building tree 124 of 215\n",
      "building tree 125 of 215\n",
      "building tree 126 of 215\n",
      "building tree 127 of 215\n",
      "building tree 128 of 215\n",
      "building tree 129 of 215\n",
      "building tree 130 of 215\n",
      "building tree 131 of 215\n",
      "building tree 132 of 215\n",
      "building tree 133 of 215\n",
      "building tree 134 of 215\n",
      "building tree 135 of 215\n",
      "building tree 136 of 215\n",
      "building tree 137 of 215\n",
      "building tree 138 of 215\n",
      "building tree 139 of 215\n",
      "building tree 140 of 215\n",
      "building tree 141 of 215\n",
      "building tree 142 of 215\n",
      "building tree 143 of 215\n",
      "building tree 144 of 215\n",
      "building tree 145 of 215\n",
      "building tree 146 of 215\n",
      "building tree 147 of 215\n",
      "building tree 148 of 215\n",
      "building tree 149 of 215\n",
      "building tree 150 of 215\n",
      "building tree 151 of 215\n",
      "building tree 152 of 215\n",
      "building tree 153 of 215\n",
      "building tree 154 of 215\n",
      "building tree 155 of 215\n",
      "building tree 156 of 215\n",
      "building tree 157 of 215\n",
      "building tree 158 of 215\n",
      "building tree 159 of 215\n",
      "building tree 160 of 215\n",
      "building tree 161 of 215\n",
      "building tree 162 of 215\n",
      "building tree 163 of 215\n",
      "building tree 164 of 215\n",
      "building tree 165 of 215\n",
      "building tree 166 of 215\n",
      "building tree 167 of 215\n",
      "building tree 168 of 215\n",
      "building tree 169 of 215\n",
      "building tree 170 of 215\n",
      "building tree 171 of 215\n",
      "building tree 172 of 215\n",
      "building tree 173 of 215\n",
      "building tree 174 of 215\n",
      "building tree 175 of 215\n",
      "building tree 176 of 215\n",
      "building tree 177 of 215\n",
      "building tree 178 of 215\n",
      "building tree 179 of 215\n",
      "building tree 180 of 215\n",
      "building tree 181 of 215\n",
      "building tree 182 of 215\n",
      "building tree 183 of 215\n",
      "building tree 184 of 215\n",
      "building tree 185 of 215\n",
      "building tree 186 of 215\n",
      "building tree 187 of 215\n",
      "building tree 188 of 215\n",
      "building tree 189 of 215\n",
      "building tree 190 of 215\n",
      "building tree 191 of 215\n",
      "building tree 192 of 215\n",
      "building tree 193 of 215\n",
      "building tree 194 of 215\n",
      "building tree 195 of 215\n",
      "building tree 196 of 215\n",
      "building tree 197 of 215\n",
      "building tree 198 of 215\n",
      "building tree 199 of 215\n",
      "building tree 200 of 215\n",
      "building tree 201 of 215\n",
      "building tree 202 of 215\n",
      "building tree 203 of 215\n",
      "building tree 204 of 215\n",
      "building tree 205 of 215\n",
      "building tree 206 of 215\n",
      "building tree 207 of 215\n",
      "building tree 208 of 215\n",
      "building tree 209 of 215\n",
      "building tree 210 of 215\n",
      "building tree 211 of 215\n",
      "building tree 212 of 215\n",
      "building tree 213 of 215\n",
      "building tree 214 of 215\n",
      "building tree 215 of 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 215 out of 215 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=ExtraTreesClassifier(bootstrap=False,\n",
       "                                                  class_weight=None,\n",
       "                                                  criterion='gini',\n",
       "                                                  max_depth=None,\n",
       "                                                  max_features='auto',\n",
       "                                                  max_leaf_nodes=None,\n",
       "                                                  min_impurity_decrease=0.0,\n",
       "                                                  min_impurity_split=None,\n",
       "                                                  min_samples_leaf=1,\n",
       "                                                  min_samples_split=2,\n",
       "                                                  min_weight_fraction_leaf=0.0,\n",
       "                                                  n_estimators='warn',\n",
       "                                                  n_jobs=None, oob_sco...\n",
       "       439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451,\n",
       "       452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464,\n",
       "       465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477,\n",
       "       478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490,\n",
       "       491, 492, 493, 494, 495, 496, 497, 498, 500])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring='balanced_accuracy',\n",
       "                   verbose=10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_rand.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 215,\n",
       " 'max_features': 0.23636363636363636,\n",
       " 'max_depth': 5.0,\n",
       " 'criterion': 'gini'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_rand.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 215 out of 215 | elapsed:    1.5s finished\n"
     ]
    }
   ],
   "source": [
    "y_ef_train_pred = et_rand.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8364638003352314"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_train,y_ef_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_params = {\"n_estimators\": [x for x in range(100,300,20)],\n",
    "             \"criterion\":[\"entropy\"],\n",
    "             \"max_depth\": [3,4,5],\n",
    "             \"max_features\": [x for x in np.arange(0.15,0.35,0.05)] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_grid = GridSearchCV(et_clf, et_params, verbose=10, n_jobs=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_projects-PtpjDyvs",
   "language": "python",
   "name": "ml_projects-ptpjdyvs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
